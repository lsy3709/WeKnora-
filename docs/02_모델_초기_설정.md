# 02. 모델 초기 설정 가이드

지식베이스를 구축하고 대화를 시작하기 전에, 사용할 LLM(거대언어모델)과 Embedding(임베딩) 모델을 설정해야 합니다.

## 1. 모델 설정 페이지 이동
로그인 후 왼쪽 메뉴 하단의 **설정 (Settings)** 아이콘을 클릭한 뒤, **모델 설정 (Model Config)** 탭을 선택합니다.

## 2. 모델 소스 선택
WeKnora는 두 가지 방식의 모델 연결을 지원합니다.

### A. Ollama (로컬 모델)
컴퓨터에 Ollama가 설치되어 실행 중이라면 로컬 모델을 사용할 수 있습니다.
1. **Ollama 설정** 탭에서 서비스 상태가 "사용 가능"인지 확인합니다.
2. 원하는 모델(예: `qwen2.5`, `llama3`)이 없다면 이름을 입력하고 **다운로드** 버튼을 클릭합니다.

### B. Remote API (원격 서비스)
OpenAI, Anthropic, DeepSeek 등 외부 API를 연결할 수 있습니다.
1. **모델 설정**에서 **모델 추가** 버튼을 클릭합니다.
2. **모델 소스**를 "Remote API"로 선택합니다.
3. API 제공업체의 **Base URL**과 **API Key**를 입력합니다.

## 3. 역할별 모델 지정
시스템이 정상적으로 동작하려면 다음 모델들이 최소 하나씩 등록되어야 합니다.
- **LLM 모델**: 실제 답변 생성용
- **임베딩 모델**: 문서 벡터화용 (차원 수 확인 필수, 예: 1536)
- **재정렬(Rerank) 모델**: (선택 사항) 검색 결과의 정확도를 높임

---
**다음 단계**: [03. 지식베이스 구축](./03_지식베이스_구축.md)에서 문서를 업로드해 보세요.
